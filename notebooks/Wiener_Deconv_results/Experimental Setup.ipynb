{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343b3a32-9ca6-4a1d-aa84-218d8465ddcd",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e61818-4988-4661-9804-711b39496f48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hemodynamic Response Function (HRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa4d1c-9f03-4b82-b903-b1869397b24e",
   "metadata": {},
   "source": [
    "Generally speaking, cognitive processing is associated with increases in neuronal firing rates. The increased neural activity leads to increased metabolic requirements for the neurons. The onset of neural activity leads to a systematic series of physiological changes in the local network of blood vessels that include changes in the cerebral blood volume per unit of brain tissue (CBV), changes in the rate of cerebral blood flow (CBF), and changes in the concentration of oxyhaemoglobin and deoxyhaemoglobin.\n",
    "\n",
    "The most common functional imaging signal is the Blood Oxygenation Level Dependent signal (BOLD), which primarily corresponds to the concentration of deoxyhaemoglobin.\n",
    "\n",
    "For the purposes of estimating the BOLD signal in an experimental paradigm, SPM makes use of a canonical haemodynamic response function (HRF). This function is assumed to be the response of the system (as reflected by the MR signal) to a brief, intense period of neural stimulation. The canonical HRF in SPM is defined as the difference of two Gamma function. The implementation, including the shape parameters, was ported from the SPM matlab implementation into julia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d29d9-968c-45df-a83c-631d5da87253",
   "metadata": {},
   "source": [
    "$h(t) = A (\\frac{t^{\\alpha_1 - 1} \\beta^{\\alpha_1} e^{-\\beta_1 t}}{\\Gamma{\\alpha_1}} - c \\frac{t^{\\alpha_2 -1} \\beta^{\\alpha_2} e^{-\\beta_2 t}}{\\Gamma (\\alpha_2) } ) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b7f61-6430-42be-8af4-60937e5192ec",
   "metadata": {},
   "source": [
    "The Repetition Time or Repeat Time (RT) parameter is passed to the hrf function. It is the temporal resolution at which the fmri timeseries was acquired. In the following I will refer to a $hrf$ function with a given RT as $hrf_{RT}$ for clarity. $hrf$ functions with varying Repetition Times are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85035fe5-be15-4ed3-9c80-e9c253dd2f74",
   "metadata": {},
   "source": [
    "![alt text](hrf_comp.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e128de-10ac-497b-a49d-d776d86bee10",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bef43f-1c16-471d-ad9e-f012a70fb14f",
   "metadata": {},
   "source": [
    "Definition Convolution: Convolution is a operation on two functions $f$ and $g$ written as $f \\ast g$. It is defined as\n",
    "    $(f \\ast g)(t) := \\int_{-\\infty}^{\\infty} f(t - \\tau) g(\\tau) d\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2681e4-b283-4cc3-be09-81e146b5bf91",
   "metadata": {},
   "source": [
    "Definition discrete convolution: For functions $f,g$ definted on the set $\\mathbb{Z}$ of integers, the discrete convolution of $f$ and $g$ is defined as \n",
    "    $(f \\ast g)[n] = \\sum_{m=-\\infty}^{\\infty}f[m] g[n-m]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59f296-952a-4354-bb47-84be5232eb4a",
   "metadata": {},
   "source": [
    "Convolutional Theorem: Consider two functions $f(x)$ and $g(x)$ with Fourier transforms $F(k)=\\mathscr{F} \\{f\\}(k)$ and $G(k)=\\mathscr{F} \\{g\\}(k)$ where $\\mathscr{F}$ denotes the Fourier transform operator. Define the convolution of $f$ and $g$ as $r(x) := (f \\ast g ) (x)$\n",
    "\n",
    "The convolutional theorem states that $R(k) := \\mathscr{F} \\{ r \\} (k) = F(k) G(k)$ \n",
    "\n",
    "Applying the inverse Fourier transform $\\mathscr{F}^{-1}$ produces the corollary: $r(x) = \\mathscr{F}^{-1} \\{ F \\cdot G \\}(x)$ where $\\cdot$ denotes point-wise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c3899a-ba29-4f30-bd35-68f0400775e5",
   "metadata": {},
   "source": [
    "When $g$ has finite support in the set $\\{ -M, -M+1, ..., M-1, M \\}$ (representing, for instance, a finite impulse response), a finite summation may be used: \n",
    "    $(f \\ast g )[n] = \\sum_{m=-M}^{M} f[n-m]g[m]$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe855d-139d-4ec9-ae72-fea45df0bfd5",
   "metadata": {},
   "source": [
    "![alt text](boxcar_hrf_conv.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970a8ee-3024-49e1-a863-90447e7cddd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1efb05f-71df-4c16-ad4c-5b693c5835e0",
   "metadata": {},
   "source": [
    "I followed the deconvolution approach presented in https://www.sciencedirect.com/science/article/pii/S1053811921008648 for fmri time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d646a-45d7-4fff-81f6-901bb7033325",
   "metadata": {},
   "source": [
    "Deconvolution is the inverse operation to convolution. Given the functions $g$ and $h$, the objective of deconvolution is to find $f$ given the convolution equation \n",
    "    $f \\ast g = h$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9723dd9-c4e1-4828-956f-f8fc0d1b1966",
   "metadata": {},
   "source": [
    "Usually, $h$ is a recorded signal and $f$ is the signal we wish to recover but has been convolved by a filter or inpulse response function $g$ when measuring/recording the signal. In (physical) measurements, the situation is usually \n",
    "    $(f \\ast g) + \\epsilon = h$ where $\\epsilon$ is the noise term of the signal.\n",
    "    \n",
    "Assuming white noise we can use the Wiener Deconvolution to recover $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95325edd-edda-47ba-93f9-db857f561eab",
   "metadata": {},
   "source": [
    "Wiener Deconvolution:\n",
    "    Given a system $y(t) = (h \\ast x)(t) + n(t)$\n",
    "\n",
    "where\n",
    "\n",
    "$x(t)$ the original signal we wish to recover\n",
    "\n",
    "$h(t)$ the known impulse response\n",
    "\n",
    "$n(t)$ additive white noise term, independent of $x(t)$\n",
    "\n",
    "$y(t)$ observed signal\n",
    "    \n",
    "    \n",
    "The goal is to find a function $g(t)$ so that we can estimate $x(t)$\n",
    "\n",
    "$\\hat{x}(t) = (g \\ast y)(t)$\n",
    "    \n",
    "where $\\hat{x}(t)$ is an estimate of $x(t)$ that minimizes the mean square error\n",
    "    \n",
    "The Wiener deconvolution filter provides such a $g(t)$. In the frequency domain the filter is written as\n",
    "\n",
    "$G(k) = \\frac{H*(k)S(k)}{\\|H(k)\\|^2 S(k) + N(k)}$\n",
    "\n",
    "where:\n",
    "\n",
    "$G(k)$ and $H(k)$ are the Fourier transforms of $g(t)$ and $h(t)$\n",
    "\n",
    "$S(k) = \\mathbb{E} [X(k)]^2$ is the mean power spectral density of the original signal $x(t)$\n",
    "\n",
    "$N(k) = \\mathbb{E} [V(k)]^2$ is the mean power spectral density of the noise $n(t)$\n",
    "\n",
    "$X(k)$, $Y(k)$ and $V(k)$ are the Fourier transforms of $x(t)$, $y(t)$ and $n(t)$ respectively.\n",
    "\n",
    "the superscript $^*$ denotes complex conjugation\n",
    "\n",
    "Using the convolution theorem we can then obtain $\\hat{X}(k) = G(k)Y(k)$ and perform an inverse Fourier transform on $\\hat{X}(k)$ to obtain $\\hat{x}(t)$.\n",
    "\n",
    "An application of the Wiener Deconvolution to the signal $x(t) = \\sin(2t) \\cdot \\cos(5t) - 1.5 \\cos(6t) \\cdot sin(2t) + 0.2 \\sin(20t)$ convoluted with $hrf_{0.2}$ and added white noise is shown below (under the assumption that the Powerspectra of the original signal and noise is known)\n",
    "\n",
    "![alt text](wiener_deconv.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7b786-88b9-40e4-aa71-fd1b93162448",
   "metadata": {},
   "source": [
    "Due to the padding of the signal edges both the observed signal and the deconvolution are longer than the original signal. When calculating metrics like the mean squared error the edges have to be removed to obtain a useful result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507866f5-7a3e-4709-98d0-d5440bc4953e",
   "metadata": {},
   "source": [
    "## Wavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51972c76-045c-4c08-b348-10d2af662dfa",
   "metadata": {},
   "source": [
    "### Continious Wavelet transform (CWT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c2068-d5c5-4f9d-9c1b-8e46fef8653c",
   "metadata": {},
   "source": [
    "The fundamental idea behind wavelets is to analyze through the scale. Wavelets are used in wavelet transformation the same way sin and cos are used in the Fourier transformation. In Fourier transformation, a function is transformed to a new basis given by sin and cos functions in frequency space.\n",
    "\n",
    "The basis functions of the Fourier transform are localized in the frequency domain, each sin/cos has a single frequency, but not in the time domain, where they are periodic and non-vanishing. This means that for periodic, continuous signals the Fourier transform only needs a small amount of coefficients to obtain a good approximation of the signal. In addition, noise limited to certain frequencies can be easily detected and filtered. \n",
    "\n",
    "On the other hand, local signals containing discontinuities cannot be approximated easily and one needs a large amount of Fourier coefficients. Furthermore, localized time information is stored in the phase of the Fourier transformation, so modifications to the signals in frequency space e.g. filtering may corrupt transient time information, leading to unwanted side effects.\n",
    "\n",
    "These problems are addressed by wavelet transformations. Wavelets are, just like sin and cos in the Fourier transformation, used as basis functions\n",
    "to represent a signal in the frequency domain. The major difference is that wavelets are localized in time and frequency domain. Therefore, wavelets are well-suited to approximate data containing sharp discontinuities. Another advantage of wavelets is that their width in time and frequency can vary, as illustrated in Figure below. This way one has long low frequency basis function for frequency analysis and short basis function to isolate discontinuities. The continuous wavelet transform can be expressed similarly to Fourier transform\n",
    "\n",
    "$F(a,b) = \\int_{\\mathbb{R}}f(x)\\psi_{(a,b)}^{\\ast}(x)dx$\n",
    "\n",
    "where * is the complex conugate and $\\psi$ is a given wavelet function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c1436-e48a-48f2-880f-8ed519cb3272",
   "metadata": {},
   "source": [
    "![alt text](STFT_and_WT.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52973cfd-ee73-459b-8c4a-041516a4f9a2",
   "metadata": {},
   "source": [
    "Source: https://commons.wikimedia.org/wiki/File:STFT_and_WT.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b6214-3dd3-4b30-b381-23eed33d37cb",
   "metadata": {},
   "source": [
    "Definition: A function $\\psi \\in L^{2}(\\mathbb{R})$ is called a Wavelet if it satifies the following conditions\n",
    "\n",
    "   1. meanfree $\\int_{\\mathbb{R}} \\psi (t) dt = 0$\n",
    "\n",
    "   2. normalised $\\sqrt{\\int_{\\mathbb{R}} \\psi(t) \\psi^{\\ast}(t) dt} = 1$\n",
    "\n",
    "In many cases an additional condition is required:\n",
    "\n",
    "   3. admissibility $\\int_{\\mathbb{R}} \\frac{\\psi(t) \\psi^{\\ast}(t)}{\\|t\\|} dt < \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34840e2c-f63f-44d1-bd6f-6fbc8c672da6",
   "metadata": {},
   "source": [
    "From a so called Mother wavelet that satisfiesthe conditions above furthur Daughter wavelets can be generated using scaling and translation\n",
    "\n",
    "$\\psi_{s, \\tau} = \\frac{1}{s} \\psi(\\frac{t-\\tau}{s})$\n",
    "\n",
    "The scale factor $s$ and the translation factor $\\tau$ determine the wavelet's width and position. This entire Wavelet family defines an orthogonal basis. By construction the basis elements are self-similar, once we know about the mother function we know everything about the basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06c5e2-eab7-4b47-97a7-4d3ce6dbfd9d",
   "metadata": {},
   "source": [
    "### Discrete Wavelet Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e39ab-2eac-4721-b265-40513e49e4c7",
   "metadata": {},
   "source": [
    "The discrete wavelet transformation (DWT) of a signal $x[n]$ can be represented as a series of filters. On each level, the signal passes through a low pass filter, resulting in the so called approximation coefficients, and a high pass filter, resulting in the so called detail coefficients.\n",
    "\n",
    "$y_{\\text{high/low}}[n] = (x \\ast f)[n] = \\sum_{k \\in $\\mathbb{Z}$} x[k]f[n-k]$\n",
    "\n",
    "with $f$ being the filter function.  Since approximately half the frequencies have been removed, half the samples can be discarded according to Nyquitâ€™s rule. Using the sub-sampling operator $\\downarrow$\n",
    "\n",
    "$(f \\downarrow k)(n) = f(kn)$\n",
    "\n",
    "we can write the transformation as \n",
    "\n",
    "$y_{high} = (x \\ast h) \\downarrow 2$\n",
    "$y_{low} = (x \\ast g) \\downarrow 2$\n",
    "\n",
    "To further increase the frequency resolution, this decomposition can be re\u0002cursively applied taking the approximation coefficients of a given level as input for the next. This so called filter bank is shown schematically below. The filters are coefficients {c0, ..., cn} calculated with help of the mother wavelet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee50170-6e5d-4820-a594-6195958835db",
   "metadata": {},
   "source": [
    "![alt text](DWT_scheme.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27f204-d2e5-4985-9c5a-922be165da89",
   "metadata": {},
   "source": [
    "### Noise Estimation and Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11792b-8ec9-4058-9004-e52fd3dd7696",
   "metadata": {},
   "source": [
    "The Wiener Deconvolution needs an estimate of the power spectra of the noise and the original signal. \n",
    "\n",
    "The noise was assumed to be gaussian white noise with mean $\\mu=0$.\n",
    "\n",
    "As proposed by Donoho 1995, the standard deviation was estimated by $\\hat{\\sigma} = MAD/0.6745$ where $MAD$ is the median absolute value of the normalized finescale wavelet coefficients. (https://www.fceia.unr.edu.ar/~jcgomez/wavelets/Donoho_1995.pdf)\n",
    "\n",
    "To estimate the original signal the noisy signal was denoised using the so called VisuShrink method, a wavelet based denoising technique. The Algorithm can be summerized as follows:\n",
    "\n",
    "1. Apply the wavelet transformation $W$ to the signal and obtain the empirical wavelet coefficients.\n",
    "\n",
    "2. Apply thresholding to the wavelet coefficients. I used hard thresholding in this work $\\Theta^0_T(x)_i = \\{ x_i \\text{ if } \\|x_i\\|>T,  0 \\text{ otherwise } \\}$\n",
    "\n",
    "3. Apply the inverse wavelet transformation $W^{\\ast}$ to thresholded coefficients to obtain the final estimator of the signal $\\tilde{f} = W^*(\\tilde x)$\n",
    "\n",
    "(https://academic.oup.com/biomet/article/81/3/425/256924?login=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e5ffe-27a9-4ec3-a00a-c28e85763e80",
   "metadata": {},
   "source": [
    "![alt text](wavelet_denoise.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3ea3e-0f7b-4bdf-aa91-26882d6b2bb7",
   "metadata": {},
   "source": [
    "## Observation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d245b-7472-478d-b0ee-9dba4e15803d",
   "metadata": {},
   "source": [
    "The observation equation used in identity TF is\n",
    "\n",
    "$\\hat{x}_{t} = B z_{t}$\n",
    "\n",
    "where $\\hat{x}_{t}$ is the estimate of the N-dimension data point $x_t$, $z_{t}$ is the M-dimensional hidden state vector and $B$ is a fixed $N \\times M$ matrix $\\mathcal{I}$ with entires\n",
    "\n",
    "$\\mathcal{I}_{i,j} = \\{1 \\text{ if } i=j \\land i,j \\leq N, 0 \\text{ else} \\}$\n",
    "\n",
    "In the case of $N=M$ this simplifies to $B=\\mathbb{1}$ the identity matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e714f0-b6dd-486b-889a-eb2e1c0940dc",
   "metadata": {},
   "source": [
    "The implication of using $\\mathcal{I}$ is splitting $z$ into an observation and a hidden or latent subspace. \n",
    "\n",
    "$z_t = [z_{t}^{obs}, z_{t}^{lat}]^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd96807-594c-449b-b43e-fbbd37a3d26c",
   "metadata": {},
   "source": [
    "I modified this observation equation by adding a convolution with the $hrf$ function\n",
    "\n",
    "$\\hat{x}_{t} = B ( hrf \\ast z_{t_0:t} )$\n",
    "\n",
    "where the latent states are convolved over time with $hrf$ and then projected from the latent to the observation space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d796f-ca7f-4cb7-9df0-6724d72c833c",
   "metadata": {},
   "source": [
    "This includes the complication that the observationsat time $t$  $x_{t}$  don't just depend on the current state $z_{t}$, but on a set of states $z_{t_0:t}$ across serveral previous time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26eca6-88db-49d0-9594-80f45749e598",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modified Teacher Forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4db2c-32fa-4b5d-ad38-bf08bbac9b68",
   "metadata": {},
   "source": [
    "Given a PLRNN $F_{\\theta}$, teacher forcing (TF) consists of regularly replacing the network's state variable $z_{t}$ with desired target values $d_t$. In weak teacher forcing, the generated state variable $z_t$ and the desired target $d_t$ are linearly interpolated using a weighting coefficient $\\alpha$\n",
    "\n",
    "$z_{t+1} = F_{\\theta} (( 1-\\alpha ) z_{t} + \\alpha d_{t} )$ ,  $\\alpha \\in (0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689ea23-4365-42a9-bccd-2a726c4519ce",
   "metadata": {},
   "source": [
    "The desired target is simply the ground truth for the observation subspace of the first $N$ dimensions and 0 in the hidden subspace of higher dimension $N+1$ to $M$\n",
    "\n",
    "$ d_t = [x_{t}, z_{t}^{lat}]^{T} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75716ddb-03fa-45b2-9fdf-e670383d54b3",
   "metadata": {},
   "source": [
    "The problem with the convolutional observation model is that it is no longer clear what the forcing signal should look like because the observations $x_{t}$ depend on multiple  latant states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5438a07-6346-430b-9852-25ec118a1b10",
   "metadata": {},
   "source": [
    "I used the Wiener deconvolution on the ground truth $x$, which we assume is convolved with a $hrf$ function, to obtain an estimate $y$ of the unconvolved signal. This estimate was then passed as forcing signal\n",
    "\n",
    "$ d_t = [y_{t}, z_{t}^{lat}]^{T} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c8c52-ce28-4b59-b5e6-98e1eb19914c",
   "metadata": {},
   "source": [
    "# Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78065d06-038d-4c14-9820-0506755af32c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Benchmarking on data without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad718c8f-0840-42f3-9d53-a2ee63b49fb8",
   "metadata": {},
   "source": [
    "1. I created a dataset of 10^5 timesteps of the Lorenz63 attractor in the chaotic regime\n",
    "2. I trained a PLRNN (shallowPLRNN) with 5000 epochs on the Lorenz63 dataset using weak Identity Teacher Forcing and Identity Mapping as Observation model\n",
    "3. Using the model trained in 2. I created 4 datasets, each containing 100 trajectories drawn from the model. In the linear case I did not further modify the data. In the other cases I convoluted the data with a $hrf_{1.2}$, a $hrf_{0.5}$ and a $hrf_{0.2}$ respectively. These datasets served as the training data for the benchmark \n",
    "4. To benchmark, I trained 100 models with the linear Identity Mapping on each of the datasets. Then I trained 100 models with the convolutional Observation model on each dataset. For the convolution I used the same $hrf$ also used to convolve the data. In the case of the unconvolved dataset I used $hrf_{1.2}$. Each model was trained for 1000 epochs.\n",
    "5. After every 25 training epochs a trajectory is generated by the model and the state space distance and Hellinger distance are calculated between the generated trajectory and the test set. In the Benchmark results I used the metrics from the epoch with the lowest state space distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa3e77-2db6-407d-9649-8e0ff120c2b9",
   "metadata": {},
   "source": [
    "![alt text](lorenz_hrf_conv.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aebbb7-fc0a-407b-8551-482ddedb9533",
   "metadata": {},
   "source": [
    "### Benchmarking on data with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549109eb-1233-409e-9680-bf103a6f66ee",
   "metadata": {},
   "source": [
    "1. I created a dataset of 10^5 timesteps of the Lorenz63 attractor in the chaotic regime\n",
    "2. I trained a PLRNN (shallowPLRNN) with 5000 epochs on the Lorenz63 dataset using weak Identity Teacher Forcing and Identity Mapping as Observation model\n",
    "3. Using the model trained in 2. I created 2 datasets, each containing 100 trajectories drawn from the model. I convoluted the data with a $hrf_{1.2}$ an added gaussian white noise with a mean $\\mu=0$ and a variance of $\\sigma=0.1$ and $\\sigma=0.01$. These datasets served as the training data for the benchmark \n",
    "4. To benchmark, I trained 100 models with the linear Identity Mapping on both datasets. Then I trained 100 models with the convolutional Observation model on each dataset. For the convolution I used the same $hrf$ also used to convolve the data. Each model was trained for 1000 epochs.\n",
    "5. After every 25 training epochs a trajectory is generated by the model and the state space distance and Hellinger distance are calculated between the generated trajectory and the test set. In the Benchmark results I used the metrics from the epoch with the lowest state space distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ed3e5-3b71-4738-90de-df1b62a4f770",
   "metadata": {},
   "source": [
    "![alt text](lorenz_hrf_conv_noise.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253060e-3f9c-4f38-bc98-6b5990188240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
